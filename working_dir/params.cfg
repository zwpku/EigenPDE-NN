[default]
dim = 2
pot_id = 5
beta = 1.0
output_dir = ./data/
eig_file_name_prefix = eigen_vector
data_filename_prefix = states_2d
log_filename = log.txt
eig_idx_k = 3
#compute_all_k_eigs = False
compute_all_k_eigs = True
namd_data_flag = True
#namd_data_flag = False
#weights in the loss function, separated by ','
eig_weight = 1.0, 0.8, 0.6, 0.3, 0.2, 0.1
#False 
[potential]
stiff_eps = 0.50
[sample_data]
delta_t = 0.001
N_state = 5e4
[NAMD]
namd_data_path = ../../MD/alanine-dipeptide/abf-fixed-alpha1.0/
namd_data_filename_prefix = test_A
pdb_path = ../../MD/pdb-files/Alanine-Dipeptide/
pdb_prefix = A
align_data_flag = True
temperature = 300
# possible value: all, nonh, angle_atoms, angle
which_data_to_use = angle
[NeuralNetArch]
arch_size_list = 2,50,50
ReLU_flag = False
[Training]
# If true, each processor reads part of the data
#distribute_data = True
#distributed_training = False
distributed_training = True
# total training step
train_max_step = 100
# the following lists should have the same length
# step at which a new stage starts
stage_list = 0, 50, 90, 1500
# parameters for each stage: batch-size, learning rate, and two penalty constants
batch_size_list = 2000, 5000, 5000, 10000 
learning_rate_list = 5e-3, 5e-3, 5e-3, 2e-2
alpha_1_list = 20.0, 20.0, 20.0, 30.0
alpha_2_list = 20.0, 20.0, 20.0, 30.0

# this flag is only useful when computing multiple eigenvalues
use_Rayleigh_quotient = True
# whether keep the eigenvalues sorted during training
sort_eigvals_in_training = True
print_every_step = 5
print_gradient_norm = True
[grid]
xmin=-3.0
xmax=3.0
nx = 300
ymin=-3.0
ymax=3.0
ny = 300
[FVD2d]
iter_n=100
error_tol=1e-2

