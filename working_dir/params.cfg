[default]
dim = 2
pot_id = 2
beta = 1.5
output_dir = ./data/
eig_file_name_prefix = eigen_vector
data_filename_prefix = states_2d
log_filename = log.txt
eig_idx_k = 1
#compute_all_k_eigs = False
compute_all_k_eigs = True
namd_data_flag = True
#namd_data_flag = False
#weights in the loss function, separated by ','
eig_weight = 1.0, 0.3, 0.6, 0.3, 0.2, 0.1
#False 
[potential]
stiff_eps = 0.50
[sample_data]
delta_t = 0.001
N_state = 1e6
# Coefficient under which the data is sampled
SDE_beta = 1.0
[NAMD]
#namd_data_path = ../../MD/alanine-dipeptide/abf-varying-200ns-6/
#namd_data_path = ../../MD/alanine-dipeptide/abf-varying-20ns/
#namd_data_path = ../../MD/alanine-dipeptide/no-abf-1500ns-300K/
namd_data_path = ../../MD/alanine-dipeptide/abf-fixed-80ns-1.0/
#namd_validation_data_path = ../../MD/alanine-dipeptide/abf-varying-20ns/
namd_validation_data_path = ../../MD/alanine-dipeptide/abf-fixed-80ns-1.0/
#namd_validation_data_path = ../../MD/alanine-dipeptide/no-abf-1500ns-300K/
#test_A
namd_data_filename_prefix = colvar-together
#namd_data_filename_prefix = run
psf_name = vacuum
# Possible value: none, trans, trans-rot
align_data_flag = trans-rot

temperature = 300
# Dampling coefficient # (unit : ps^{-1})
damping_coeff = 1.0
# Possible value: all, nonh, angle_atoms, angle
which_data_to_use = nonh
# If biased MD data are used, the files .colvar.traj 
# and .pmf are also required.
use_biased_data = True

weight_threshold_to_remove_states = 1e-5
[NeuralNetArch]
# Size of inner layers (without input/output layers)
arch_size_list = 40,30,30,40
ReLU_flag = False
[Training]
# total training step
train_max_step = 70000
# the following lists should have the same length
# step at which a new stage starts
stage_list = 0, 10000, 20000, 69900
# parameters for each stage: batch-size, learning rate, and two penalty constants
batch_size_list = 10000, 20000, 20000, 40000 
learning_rate_list = 1e-2, 5e-3, 5e-3, 1e-3
alpha_1_list = 20.0, 20.0, 20.0, 20.0
alpha_2_list = 20.0, 20.0, 20.0, 20.0

# Use Rayleigh quotient or energy in loss function
use_Rayleigh_quotient = True
# Whether keep the eigenvalues sorted during training
sort_eigvals_in_training = True

print_every_step = 10
#print_gradient_norm = True

# When true, only use (normalized) orthonality constraints in penalty term
use_reduced_2nd_penalty = False
# Whether to perform constraint step
include_constraint_step = False
# Apply constraint step after certain training steps  
constraint_first_step = 1000
# After performing constraint step, whether still include penalty term in loss function 
constraint_penalty_method = False
# Convergence criteria for constraint step
constraint_tol = 1e-2
# How often to perform constraint step
constraint_how_often = 3
# Learning rate used in constraint step
constraint_learning_rate= 1e-3
# Maximal training steps in constraint step
constraint_max_step = 100
[grid]
xmin=-3.0
xmax=3.0
nx = 500
ymin=-3.0
ymax=3.0
ny = 300
[FVD2d]
iter_n=100
error_tol=1e-2

