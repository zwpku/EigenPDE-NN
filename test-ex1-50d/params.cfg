[default]
eig_file_name_prefix = eigen_vector
log_filename = log.txt
md_data_flag = False
load_data_how_often = 1
[SDE]
dim = 2
pot_id = 5
beta = 1.0
stiff_eps = 0.50
delta_t = 0.001
N_state = 5e6
# Coefficient under which the data is sampled
SDE_beta = 1.0
data_filename_prefix = states_50d
data_filename_prefix_validation = states_50d_test

[NeuralNetArch]
# Size of inner layers (without input/output layers)
arch_size_list = 20,20,20
# Activation function. 
# Possible values: ELU, LogSigmoid, ReLU, CELU, Sigmoid, Softplus, Tanh, Tanhshrink
# CELU will be used when function with given name does not exist!
activation_name = Tanh
[Training]
eig_k = 3
# total training step
train_max_step = 7100
# Whether to start from a trained model 
load_init_model = False
# Filename of trained model
init_model_name = eigen_vector.pt
#weights in the loss function, separated by ','
eig_weight = 1.0, 0.8, 0.6, 0.3, 0.2, 0.1
# the following lists should have the same length
# step at which a new stage starts
stage_list = 0, 7000 
# parameters for each stage: batch-size, learning rate, and two penalty constants
batch_size_list = 5000, 20000
learning_rate_list = 5e-3, 5e-3
alpha_list = 20.0, 20.0

# Whether keep the eigenvalues sorted during training
sort_eigvals_in_training = True

print_every_step = 10

[grid]
xmin=-3.0
xmax=3.0
nx = 500
ymin=-3.0
ymax=3.0
ny = 300
[FVD2d]
iter_n=1000
error_tol=1e-4
